{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sw/hw.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Fh3QEn1hWAJV",
        "Ladw-mcc-Mxx",
        "AUAKeSq69Ckf",
        "wrTfn4v6G4ef",
        "k5bJqOF32fIM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fzMETgA2cc84",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "import seaborn as sns\n",
        "\n",
        "# import matplotlib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQWxcgrfHXYx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "96a7a756-4896-4522-bcb8-86a3ad0edba6"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5807c02e-bdad-458a-952d-33b0c420a808\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5807c02e-bdad-458a-952d-33b0c420a808\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving testdata_v3.csv to testdata_v3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fh3QEn1hWAJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# data visualization:"
      ]
    },
    {
      "metadata": {
        "id": "BD38F0q8V_Ox",
        "colab_type": "code",
        "outputId": "346dbefd-799e-4c0a-eccd-a1b84851fa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "cell_type": "code",
      "source": [
        "# from pandas.tools.plotting import parallel_coordinates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "column_names = [\"g_x\", \"g_y\", \"g_z\", \"a_x\", \"a_y\", \"a_z\", \"target\"]\n",
        "\n",
        "df = pd.read_csv(\"testdata.csv\", names= column_names)\n",
        "# print(df)\n",
        "target = df.target\n",
        "count = 0\n",
        "for i, data in enumerate(target):\n",
        "  if count<10:\n",
        "    target[i] = count\n",
        "    \n",
        "  else:\n",
        "    count = 0\n",
        "    target[i] = count\n",
        "  count += 1\n",
        "# print(target)\n",
        "\n",
        "plt.plot(target, df.filter(items = ['a_x',0:9]))\n",
        "plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-7ac9e4c6a2a2>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    plt.plot(target, df.filter(items = ['a_x',0:9]))\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Ladw-mcc-Mxx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# neural network "
      ]
    },
    {
      "metadata": {
        "id": "otdDtE_GJ1KL",
        "colab_type": "code",
        "outputId": "13b11edb-2c6a-4d22-f047-f372bd5dc972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "cell_type": "code",
      "source": [
        "# train_df, test_df = train_test_split(df, test_size =0.2)\n",
        "column_names = [\"g_x\", \"g_y\", \"g_z\", \"a_x\", \"a_y\", \"a_z\", \"target\"]\n",
        "df = pd.read_csv(\"testdata_final.csv\", names = column_names)\n",
        "print(df)\n",
        "\n",
        "# for i,row in df.iterrows():\n",
        "#   if (row[6] != 0):\n",
        "#     row[7] = 1\n",
        "#   else:\n",
        "#     row[7] = 0\n",
        "# print(df)\n",
        "# print(df)\n",
        "target = df.target\n",
        "\n",
        "train_labels = target[:690]\n",
        "test_labels = target[690:]\n",
        "# print(train_label.shape)\n",
        "\n",
        "\n",
        "df.drop(['target', 'g_y','g_z','g_x'],axis = 1 , inplace = True)\n",
        "train_df = df[:690]\n",
        "test_df = df[690:]\n",
        "# print(train_df.shape)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-db43c25a0430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"g_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"g_z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a_z\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testdata_final.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for i,row in df.iterrows():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'testdata_final.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TNElLLVdhGr1",
        "colab_type": "code",
        "outputId": "5c20a28b-4f9e-4360-e219-2b73fb93f546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "# ReLU Activation\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "x = np.arange(-1, 1, .1)\n",
        "plt.plot(x, relu(x))\n",
        "plt.title(\"ReLU Activation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AUAKeSq69Ckf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# classification:"
      ]
    },
    {
      "metadata": {
        "id": "s7ZUp3IUhOxR",
        "colab_type": "code",
        "outputId": "cf7d53d2-79f8-427d-a50f-20baeeb15837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's first make sure the shape and type of our data is correct.\n",
        "# Convert data to float32 datatype and labels to int64 datatype.\n",
        "train_data = np.array(train_df)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "test_data = np.array(test_df)\n",
        "test_label = np.array(test_label)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "train_labels = tf.cast(train_label, tf.int64)\n",
        "test_data = tf.cast(test_data, tf.float32)\n",
        "test_labels = tf.cast(test_label, tf.int64)\n",
        "\n",
        "# When working with images, TensorFlow needs them to be shape [H, W, C], but \n",
        "# our data is just [H, W] right now since its black and white. Let's add a extra channel axis.\n",
        "# train_data = train_data[..., tf.newaxis]\n",
        "# test_data = test_data[..., tf.newaxis]\n",
        "\n",
        "# Now were ready to create Tensorflow Datasets!\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "\n",
        "# Finally, let's shuffle our training data and batch it so its more efficient.\n",
        "train_dataset = train_dataset.shuffle(1000).batch(10)\n",
        "test_dataset = test_dataset.batch(10)\n",
        "\n",
        "\n",
        "print(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((?, 3), (?,)), types: (tf.float32, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e0Wx5YCJzjTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We create a model that is a subclass of tf.keras.Model. This means that it inherits from keras but allows us to define new operations as well.\n",
        "class Model(tf.keras.Model):\n",
        "  # Init function is called when model is first built.\n",
        "  def __init__(self):\n",
        "    # Using super calls the init function for this classes parent.\n",
        "    super(Model, self).__init__()\n",
        "    # Define weight tensor, should be 10 values for 10 output classes.\n",
        "    self.W = tf.Variable(np.zeros(shape=[3, 10], dtype=np.float32), name='weight')\n",
        "    # Similarly define a bias for each neuron.\n",
        "    self.B = tf.Variable(np.zeros(10, dtype=np.float32), name='bias')\n",
        "    # Need to be able to squish the inputs down to a flat tensor for weight multiplication.\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "  \n",
        "  # Call function applies the weights and bias of the model to the passed inputs.\n",
        "  def call(self, inputs):\n",
        "    # Need inputs to be flat for dense layer.\n",
        "    flat_inputs = self.flatten(inputs)\n",
        "    # Apply matrix multiplication with weights and add bias to results.\n",
        "    return tf.matmul(flat_inputs, self.W) + self.B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kyqnS1hA42dO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pass in the model being trained, the inputs, and the correct labels.\n",
        "def loss(model, inputs, targets):\n",
        "  # Get the guess of the model.\n",
        "  guess = model(inputs)\n",
        "  \n",
        "  # Before subtracting from guess, must make labels \"one-hot\", instead of label 3, we want [0, 0, 0, 1, 0, 0, ...]\n",
        "  targets = tf.one_hot(targets, depth=10)\n",
        "  # Also cast to float for proper subtraction.\n",
        "  targets = tf.cast(targets, tf.float32)\n",
        "  # Find distance between guess and correct answer.\n",
        "  error = guess - targets\n",
        "  # Average the error across each label and square to avoid negatives.\n",
        "  return tf.reduce_mean(tf.square(error))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nqQkGKQ5wox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pass model, inputs, and correct labels.\n",
        "def grad(model, inputs, targets):\n",
        "  # Keep track of gradients within this scope.\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Compute the loss for the current input sample.\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "    # Now find gradient of loss with respect to our model's variables.\n",
        "    grads = tape.gradient(loss_value, [model.W, model.B])\n",
        "  return grads\n",
        "\n",
        "# Use a simple SGD optimizer.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ewbKa9WW53n-",
        "colab_type": "code",
        "outputId": "7006c9f8-af99-4e56-dabc-b7dbe67bc439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Create an instance of our model.\n",
        "model = Model()\n",
        "losses = []\n",
        "\n",
        "# Go through the training data 5 times.\n",
        "for epoch in range(3):\n",
        "  # Iterate through samples of training data.\n",
        "  for i, (data, label) in enumerate(train_dataset):\n",
        "    # Compute loss and gradients for current batch.\n",
        "    grads = grad(model, data, label)\n",
        "    # Apply computed gradients using SGD to update our variables.\n",
        "    optimizer.apply_gradients(zip(grads, [model.W, model.B]), global_step=tf.train.get_or_create_global_step())\n",
        "    \n",
        "    # Print the loss every 200 batches\n",
        "    if i % 200 == 0:\n",
        "      L = loss(model, data, label)\n",
        "      print(\"Loss at step %d: %.3f\" % (i, L))\n",
        "      losses.append(L)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 0: 40864508.000\n",
            "Loss at step 0: nan\n",
            "Loss at step 0: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wrTfn4v6G4ef",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# regression"
      ]
    },
    {
      "metadata": {
        "id": "tbzHNogQB0xp",
        "colab_type": "code",
        "outputId": "1d7ba3b8-54df-428d-fe92-4c435d880b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "NN_model = Sequential()\n",
        "\n",
        "# train_data = tf.cast(train_df, tf.float32)\n",
        "train_labels = tf.cast(train_labels, tf.int64)\n",
        "# test_data = tf.cast(test_df, tf.float32)\n",
        "test_labels = tf.cast(test_labels, tf.int64)\n",
        "\n",
        "train_data = np.asarray(train_df)\n",
        "train_labels = np.asarray(train_labels)\n",
        "train_data = train_data.astype(np.float)\n",
        "train_labels = train_labels.astype(np.float)\n",
        "\n",
        "test_data = np.asarray(test_df)\n",
        "test_labels = np.asarray(test_labels)\n",
        "test_data = test_data.astype(np.float)\n",
        "test_labels = test_labels.astype(np.float)\n",
        "\n",
        "# The Input Layer :\n",
        "# print(train_data.shape[1])\n",
        "input_dim= int((train_data.shape[1]))\n",
        "print(input_dim)\n",
        "\n",
        "verbose, epochs, batch_size = 0, 15, 10\n",
        "\n",
        "# model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "# model = Sequential()\n",
        "# model.add(tf.keras.layers.LSTM(10, input_shape=4))\n",
        "# model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\n",
        "# NN_model.add(Dense(128, kernel_initializer='normal',input_dim = input_dim, activation='relu'))\n",
        "\n",
        "# # The Hidden Layers :\n",
        "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# # The Output Layer :\n",
        "# NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "# NN_model.compile (loss='mean_absolute_error', optimizer=tf.train.AdamOptimizer(), metrics=['mean_absolute_error'])\n",
        "NN_model.summary()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-67692a222e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# model = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# model.add(tf.keras.layers.LSTM(10, input_shape=4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2386\u001b[0;31m         \u001b[0mfeed_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_output_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2387\u001b[0m         \u001b[0mfeed_output_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0;31m# Sample weighting not supported in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_feed_output_names'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "C_WBF-uaMkyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_name = 'Weights-best.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4AIBEFchMq0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "NN_model.fit(train_data, train_labels, epochs=200, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHvGuBpLNqy2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load wights file of the best model :\n",
        "# print(weights)\n",
        "\n",
        "\n",
        "wights_file = 'Weights-best.hdf5' # choose the best checkpoint \n",
        "NN_model.load_weights(wights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer=tf.train.AdamOptimizer(), metrics=['mean_absolute_error'])\n",
        "  \n",
        "#   sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keYAXxFhcMr4",
        "colab_type": "code",
        "outputId": "563d869d-4b6e-4aed-ba1d-f656c1082b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = NN_model.predict(test_data)\n",
        "# print(predictions)\n",
        "count = 0\n",
        "for i,prediction in enumerate(predictions):\n",
        "#   print(prediction[0])\n",
        "#   print(test_lab)\n",
        "  if abs(prediction[0] - test_labels[i])<0.5:\n",
        "    count += 1\n",
        "\n",
        "accuracy = count/len(test_label)\n",
        "print(\"accuracy: %f%%\" %(accuracy*100))\n",
        "# score = NN_model.evaluate(test_data, test_label, verbose=0)\n",
        "# print(score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 70.503597%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5bJqOF32fIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Forest Regression:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "alQTfvJ32-vS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "data training"
      ]
    },
    {
      "metadata": {
        "id": "7jAKDQGqua_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_df, test_df = train_test_split(df, test_size =0.2)\n",
        "column_names = [\"g_x\", \"g_y\", \"g_z\", \"a_x\", \"a_y\", \"a_z\", \"target\"]\n",
        "\n",
        "df = pd.read_csv(\"testdata_final (2).csv\", names = column_names)\n",
        "# df = df.values\n",
        "# for i,data in enumerate (df):\n",
        "  \n",
        "# print(df.values)\n",
        "target = df.target\n",
        "\n",
        "# count = 0\n",
        "# for i, data in enumerate(target):\n",
        "#   if count<10:\n",
        "#     target[i] = count\n",
        "    \n",
        "#   else:\n",
        "#     count = 0\n",
        "#     target[i] = count\n",
        "#   count += 1\n",
        "\n",
        "train_label = target[:690]\n",
        "test_label = target[690:]\n",
        "# print(train_label)\n",
        "# print(test_label)\n",
        "df.drop(['target', 'g_y','g_z','a_y','a_z', 'g_x'],axis = 1 , inplace = True)\n",
        "train_df = df[:690]\n",
        "test_df = df[690:]\n",
        "\n",
        "# print(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4npMy5kIyIk9",
        "colab_type": "code",
        "outputId": "0b7f6e2e-dcf2-4f42-fe13-b8e45038c5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# train_X, val_X, train_y, val_y = train_test_split(train_df, train_label, test_size = 0.25, random_state = 14)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(train_df,train_label)\n",
        "\n",
        "# Get the mean absolute error on the validation data\n",
        "predicted_prices = model.predict(test_df)\n",
        "MAE = mean_absolute_error(test_label , predicted_prices)\n",
        "print('Random forest validation MAE = ', MAE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random forest validation MAE =  0.45650980392156865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3H9CzNeW3CY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "data testing"
      ]
    },
    {
      "metadata": {
        "id": "Uw6QOT2329Qp",
        "colab_type": "code",
        "outputId": "bc455f60-25a7-4df9-ee43-2d5d2c5c99f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "prediction = model.predict(test_df)\n",
        "\n",
        "\n",
        "labels = np.array(test_label)\n",
        "# print(prediction)\n",
        "correct = 0\n",
        "for i, data in enumerate (prediction):\n",
        "  if data == labels[i]:\n",
        "#     print(data)\n",
        "#     print(\"correct\")\n",
        "    correct += 1\n",
        "#   else:\n",
        "#     print(data)\n",
        "#     print(\"incorrect\")\n",
        "accuracy = correct / len(test_label)\n",
        "print(\"accuracy: %f% %\" %(accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 24.705882%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JGF5b1-z4Wlq",
        "colab_type": "code",
        "outputId": "9fcb9202-6a02-44b7-89a9-d108578d6631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aATX4nI2looV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# testing:"
      ]
    },
    {
      "metadata": {
        "id": "pKA7RKhD0yXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "bdf68be5-4335-476e-ec69-9cfff5f29df8"
      },
      "cell_type": "code",
      "source": [
        "column_names = [\"g_x\", \"g_y\", \"g_z\", \"a_x\", \"a_y\", \"a_z\", \"step\"]\n",
        "df = pd.read_csv(\"testdata_v3.csv\", names = column_names)\n",
        "df['target'] = 0\n",
        "\n",
        "for i,row in df.iterrows():\n",
        "  if (row[6] != 0):\n",
        "    row[7] = 1\n",
        "  else:\n",
        "    row[7] = 0\n",
        "print(df)\n",
        "target = df.target\n",
        "\n",
        "train_labels = target[:690]\n",
        "test_labels = target[690:]\n",
        "\n",
        "df.drop(['target', 'g_y','g_z','g_x'],axis = 1 , inplace = True)\n",
        "train_df = df[:690]\n",
        "test_df = df[690:]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       g_x    g_y    g_z    a_x    a_y    a_z  step  target\n",
            "0    -1065    341   -547   4872   -172  16960     1       1\n",
            "1    -1264    116   -330   5020    176  17032     2       1\n",
            "2     -826     -1  -1048   4812    440  16672     3       1\n",
            "3     2573    362  -3953   4456   3256  17928     4       1\n",
            "4     2589  -3712 -10000    652  14764  17908     5       1\n",
            "5    -2199    131   3280  -1512   8068  13856     6       1\n",
            "6    -2109   1786  18115  -2000 -32768  17008     7       1\n",
            "7     2943  -1237    735   9356  -9796  14024     8       1\n",
            "8    -2333   2480   -627   5244   2744  17188     9       1\n",
            "9    -1028   -212  -2210   4048   3364  18204    10       1\n",
            "10    -924    251   -337 -10180   8372   9052     0       0\n",
            "11    -928    242   -320 -10264   8272   9020     0       0\n",
            "12    -930    252   -318 -10204   8248   8812     0       0\n",
            "13    -917      0   -300 -10148   8168   8972     0       0\n",
            "14    -914    509   -338 -10212   8300   8788     0       0\n",
            "15    -921    249   -301 -10292   7960   8824     0       0\n",
            "16    -935      5   -335 -10228   8320   9176     0       0\n",
            "17    -936    254   -344 -10392   8376   8912     0       0\n",
            "18    -921    256   -315 -10448   8296   9064     0       0\n",
            "19    -951    272   -344 -10212   8300   8964     0       0\n",
            "20   -1087    147   -444   7164  -1132  16356     1       1\n",
            "21   -1232    -19  -1085   7340   -940  15868     2       1\n",
            "22    -438    224  -1253   7132   1792  15304     3       1\n",
            "23     360   1205    331   7012   1876  16384     4       1\n",
            "24    2050  -3603 -11824   8928  13252  15700     5       1\n",
            "25  -11133   3468  17336   3044  11732  10664     6       1\n",
            "26     772  -3691  17856   5812 -15168  19620     7       1\n",
            "27    2165   3953   6110   8472 -12080  12412     8       1\n",
            "28      -6    583   -640   6996  -2804  17008     9       1\n",
            "29   -1894     18   -310   6808  -3348  17224    10       1\n",
            "..     ...    ...    ...    ...    ...    ...   ...     ...\n",
            "800  -1871    957  -3820   1384    456  17188     1       1\n",
            "801     19    725  -2705   1668    456  17512     2       1\n",
            "802   -769    206  -1382   1628      4  16788     3       1\n",
            "803  -1120    671    682   1156   1204  17436     4       1\n",
            "804    630   -116   2897  -1608   2404  17688     5       1\n",
            "805  -2420  -2125  10435  -5380   9412  17672     6       1\n",
            "806  -4422 -13240  31187  -6916   5912   7736     7       1\n",
            "807   3093  -8707  21523  12348 -11548  13464     8       1\n",
            "808   2212  -2254   2514  14804 -13976  13460     9       1\n",
            "809    -22    674  -1211   3972  -7644  13872    10       1\n",
            "810   -914    253   -301 -10180   8240   8840     0       0\n",
            "811   -942    225   -318 -10204   8332   8964     0       0\n",
            "812   -950    213   -348 -10196   8296   8988     0       0\n",
            "813   -950      7   -351  -9992   8372   8852     0       0\n",
            "814   -956    511   -339 -10244   8312   8980     0       0\n",
            "815   -925    235   -305 -10320   8272   8988     0       0\n",
            "816   -932    217   -325 -10188   8324   9196     0       0\n",
            "817   -940    244   -318 -10400   8320   8900     0       0\n",
            "818   -931    253   -322 -10204   8332   9068     0       0\n",
            "819   -945    271   -333 -10304   8264   9028     0       0\n",
            "820   -683    294   -312   3184  -1916  16992     1       1\n",
            "821   -643     29    -22   2988  -1796  17176     2       1\n",
            "822   -794    -60   -161   3016  -1068  17020     3       1\n",
            "823  -1466   -111   1246   2100   -488  16968     4       1\n",
            "824     -5   -102   5079   -152   2004  17736     5       1\n",
            "825    541  -2986   8388  -2652   3224  19040     6       1\n",
            "826  -5906  -7857  17447  -3052   -972  14624     7       1\n",
            "827  -9730  -5344  14606   5288 -11568   8944     8       1\n",
            "828  -1087   -398   7962   8236 -15956  15048     9       1\n",
            "829   1196   1292  -1029  10256 -11732  15904    10       1\n",
            "\n",
            "[830 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q7h8sIWKGU2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cadaa9fd-1a52-4262-cafd-a4404bdc00cf"
      },
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_df)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "test_data = np.array(test_df)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "train_labels = tf.cast(train_labels, tf.int64)\n",
        "test_data = tf.cast(test_data, tf.float32)\n",
        "test_labels = tf.cast(test_labels, tf.int64)\n",
        "# print(train_labels)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "\n",
        "\n",
        "# Finally, let's shuffle our training data and batch it so its more efficient.\n",
        "train_dataset = train_dataset.batch(10)\n",
        "test_dataset = test_dataset.batch(10)\n",
        "print(train_dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((?, 4), (?,)), types: (tf.float32, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NiTIwZ_Z4sAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "#     self.dense0 = tf.keras.layers.Dense(128, activation='relu')\n",
        "    self.dense1 = tf.keras.layers.CuDNNLSTM(units=4, stateful=True)\n",
        "#     self.dense2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
        "    self.dense3 = tf.keras.layers.Dense(2)\n",
        "    \n",
        "# lstm_model.add(tf.keras.layers.LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, stateful=True))\n",
        "# lstm_model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
        "  def call(self, inputs):\n",
        "    x = self.flatten(inputs)\n",
        "#     x = self.dense0(x)\n",
        "    x = self.dense1(x)\n",
        "#     x = self.dense2(x)\n",
        "    x = self.dense3(x)\n",
        "    return x\n",
        "def loss(model, inputs, targets):\n",
        "  guess = model(inputs)\n",
        "  return tf.losses.sparse_softmax_cross_entropy(targets, guess)\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    L = loss(model, inputs, targets)\n",
        "    grads = tape.gradient(L, model.trainable_variables)\n",
        "  return grads\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hFXaxVr1F371",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(model, dataset):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, (data, label) in enumerate (dataset):\n",
        "    guesses = model(data)\n",
        "    best_guesses = tf.argmax(guesses, axis = -1)\n",
        "    correct += tf.count_nonzero(tf.equal(best_guesses, label))\n",
        "    total += data.shape[0]\n",
        "    return (correct/total).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UyTPUHvwF63g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, dataset, optimizer):\n",
        "  losses = []\n",
        "  for epoch in range(5):\n",
        "    for i, (data, label) in enumerate(dataset):\n",
        "      grads = grad(model,data, label)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step=tf.train.get_or_create_global_step())\n",
        "      if i %200 == 0:\n",
        "        L = loss(model, data, label)\n",
        "        print(\"loss at step %d : %.3f \" %(i,L))\n",
        "        losses.append(L)\n",
        "  return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJ51UcetF9jQ",
        "colab_type": "code",
        "outputId": "089f9702-3f1e-4db2-9be1-da833fde2308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1323
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
        "losses = train_model(model, train_dataset, optimizer)\n",
        "test_acc = test_model(model, test_dataset)\n",
        "print(\"accuracy: %f% %\" %(test_acc*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-14839ba26cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy: %f% %\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e43c486b21ff>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ce630c2d0326>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, inputs, targets)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ce630c2d0326>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(model, inputs, targets)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ce630c2d0326>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     x = self.dense0(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#     x = self.dense2(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     input_spec.assert_input_compatibility(\n\u001b[0;32m-> 1591\u001b[0;31m         self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer cu_dnnlstm_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [10, 4]"
          ]
        }
      ]
    }
  ]
}